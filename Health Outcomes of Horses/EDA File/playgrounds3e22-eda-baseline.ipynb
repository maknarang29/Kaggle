{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# <div style= \"font-family: Cambria; font-weight:bold; letter-spacing: 0px; color:black; font-size:120%; text-align:left;padding:3.0px; background: #cceeff; border-bottom: 8px solid #004466\" > TABLE OF CONTENTS<br><div>  \n* [IMPORTS](#1)\n* [INTRODUCTION](#2)\n    * [CONFIGURATION](#2.1)\n    * [CONFIGURATION PARAMETERS](#2.2)    \n    * [DATASET COLUMNS](#2.3)\n* [PREPROCESSING](#3)\n* [ADVERSARIAL CV](#4)\n* [EDA AND VISUALS](#5) \n* [DATA TRANSFORMS](#6)\n* [MODEL TRAINING](#7)    \n* [ENSEMBLE AND SUBMISSION](#8)  \n* [PLANNED WAY FORWARD](#9)     ","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19"}},{"cell_type":"markdown","source":"<a id=\"1\"></a>\n# <div style= \"font-family: Cambria; font-weight:bold; letter-spacing: 0px; color:black; font-size:120%; text-align:left;padding:3.0px; background: #cceeff; border-bottom: 8px solid #004466\" > IMPORTS<br> <div> ","metadata":{}},{"cell_type":"code","source":"%%time \n\n# Installing select libraries:-\nfrom gc import collect;\nfrom warnings import filterwarnings;\nfilterwarnings('ignore');\nfrom IPython.display import clear_output;\n\n!pip install -q --upgrade scipy;\n!pip install -q category_encoders;\n\nclear_output();\nprint();\ncollect();","metadata":{"execution":{"iopub.status.busy":"2023-09-12T22:42:50.787961Z","iopub.execute_input":"2023-09-12T22:42:50.788682Z","iopub.status.idle":"2023-09-12T22:43:21.263064Z","shell.execute_reply.started":"2023-09-12T22:42:50.788633Z","shell.execute_reply":"2023-09-12T22:43:21.262174Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"%%time\n\n# General library imports:-\nfrom copy import deepcopy;\nimport pandas as pd;\nimport numpy as np;\nfrom scipy.stats import mode, kstest, normaltest, shapiro, anderson, jarque_bera;\nfrom collections import Counter;\nfrom itertools import product;\nfrom colorama import Fore, Style, init;\nfrom warnings import filterwarnings;\nfilterwarnings('ignore');\n\nfrom tqdm.notebook import tqdm;\nimport seaborn as sns;\nimport matplotlib.pyplot as plt;\n%matplotlib inline\n\nfrom pprint import pprint;\n\nprint();\ncollect();\nclear_output();","metadata":{"execution":{"iopub.status.busy":"2023-09-12T22:43:21.264867Z","iopub.execute_input":"2023-09-12T22:43:21.265172Z","iopub.status.idle":"2023-09-12T22:43:22.570188Z","shell.execute_reply.started":"2023-09-12T22:43:21.265146Z","shell.execute_reply":"2023-09-12T22:43:22.568988Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"%%time \n\n# Importing model and pipeline specifics:-\nfrom category_encoders import OrdinalEncoder, OneHotEncoder;\n\n# Pipeline specifics:-\nfrom sklearn.preprocessing import RobustScaler, MinMaxScaler, StandardScaler;\nfrom sklearn.impute import SimpleImputer as SI;\nfrom sklearn.model_selection import (RepeatedStratifiedKFold as RSKF, \n                                     StratifiedKFold as SKF,\n                                     KFold, \n                                     RepeatedKFold as RKF, \n                                     cross_val_score);\nfrom sklearn.inspection import permutation_importance;\nfrom sklearn.feature_selection import mutual_info_classif, RFE;\nfrom sklearn.pipeline import Pipeline, make_pipeline;\nfrom sklearn.base import BaseEstimator, TransformerMixin;\nfrom sklearn.compose import ColumnTransformer;\n\n# ML Model training:-\nfrom sklearn.metrics import f1_score, confusion_matrix;\nfrom xgboost import DMatrix, XGBClassifier;\nfrom lightgbm import LGBMClassifier, log_evaluation, early_stopping;\nfrom catboost import CatBoostClassifier, Pool;\n\n# Ensemble and tuning:-\nimport optuna;\nfrom optuna import Trial, trial, create_study;\nfrom optuna.samplers import TPESampler, CmaEsSampler;\noptuna.logging.set_verbosity = optuna.logging.ERROR;\n\nclear_output();\nprint();\ncollect();","metadata":{"execution":{"iopub.status.busy":"2023-09-12T22:43:22.572274Z","iopub.execute_input":"2023-09-12T22:43:22.572901Z","iopub.status.idle":"2023-09-12T22:43:27.131507Z","shell.execute_reply.started":"2023-09-12T22:43:22.572858Z","shell.execute_reply":"2023-09-12T22:43:27.130265Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"%%time \n\n# Setting rc parameters in seaborn for plots and graphs- \n# Reference - https://matplotlib.org/stable/tutorials/introductory/customizing.html:-\n# To alter this, refer to matplotlib.rcParams.keys()\n\nsns.set({\"axes.facecolor\"       : \"#ffffff\",\n         \"figure.facecolor\"     : \"#ffffff\",\n         \"axes.edgecolor\"       : \"#000000\",\n         \"grid.color\"           : \"#ffffff\",\n         \"font.family\"          : ['Cambria'],\n         \"axes.labelcolor\"      : \"#000000\",\n         \"xtick.color\"          : \"#000000\",\n         \"ytick.color\"          : \"#000000\",\n         \"grid.linewidth\"       : 0.75,  \n         \"grid.linestyle\"       : \"--\",\n         \"axes.titlecolor\"      : '#0099e6',\n         'axes.titlesize'       : 8.5,\n         'axes.labelweight'     : \"bold\",\n         'legend.fontsize'      : 7.0,\n         'legend.title_fontsize': 7.0,\n         'font.size'            : 7.5,\n         'xtick.labelsize'      : 7.5,\n         'ytick.labelsize'      : 7.5,        \n        });\n\n# Color printing    \ndef PrintColor(text:str, color = Fore.BLUE, style = Style.BRIGHT):\n    \"Prints color outputs using colorama using a text F-string\";\n    print(style + color + text + Style.RESET_ALL); \n\n# Making sklearn pipeline outputs as dataframe:-\nfrom sklearn import set_config; \nset_config(transform_output = \"pandas\");\npd.set_option('display.max_columns', 50);\npd.set_option('display.max_rows', 50);\n\nprint();\ncollect();\n","metadata":{"execution":{"iopub.status.busy":"2023-09-12T22:43:27.135486Z","iopub.execute_input":"2023-09-12T22:43:27.135967Z","iopub.status.idle":"2023-09-12T22:43:27.276453Z","shell.execute_reply.started":"2023-09-12T22:43:27.135924Z","shell.execute_reply":"2023-09-12T22:43:27.275296Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<a id=\"2\"></a>\n# <div style= \"font-family: Cambria; font-weight:bold; letter-spacing: 0px; color:black; font-size:120%; text-align:left;padding:3.0px; background: #cceeff; border-bottom: 8px solid #004466\" > INTRODUCTION<br><div> ","metadata":{}},{"cell_type":"markdown","source":"| Version<br>Number | Version Details | Best CV score| Single/ Ensemble|\n| :-: | --- | :-: | :-: |\n| **V1** |* EDA, plots and secondary features and encoding<br>* No scaling<br> * Used original data<br>* Tree based ML models and basic ensemble|0.71275|Simple blend |","metadata":{}},{"cell_type":"markdown","source":"<a id=\"2.1\"></a>\n## <div style= \"font-family: Cambria; font-weight:bold; letter-spacing: 0px; color:#ffffff; font-size:120%; text-align:left;padding:3.0px; background: #0059b3; border-bottom: 8px solid #e6e6e6\" > CONFIGURATION<br><div> ","metadata":{}},{"cell_type":"code","source":"%%time\n\n# Configuration class:-\nclass CFG:\n    \"Configuration class for parameters and CV strategy for tuning and training\";\n    \n    # Data preparation:-   \n    version_nb         = 1;\n    test_req           = \"N\";\n    gpu_switch         = \"OFF\"; \n    state              = 42;\n    target             = 'outcome';\n    episode            = 22;\n    path               = f\"/kaggle/input/playground-series-s3e{episode}/\";\n    orig_path          = f\"/kaggle/input/horse-survival-dataset/horse.csv\";\n    \n    dtl_preproc_req    = \"Y\";\n    adv_cv_req         = \"N\";\n    ftre_plots_req     = \"Y\";\n    ftre_imp_req       = \"Y\";\n    \n    # Data transforms and scaling:-    \n    conjoin_orig_data  = \"Y\";\n    sec_ftre_req       = \"Y\";\n    scale_req          = \"N\";\n    # NOTE---Keep a value here even if scale_req = N, this is used for linear models:-\n    scl_method         = \"Z\"; \n    enc_method         = 'Label';\n    lesion_OH_req      = \"N\";\n    tgt_mapper         = {\"lived\": 2, \"euthanized\": 1, \"died\": 0};\n    \n    # Model Training:- \n    baseline_req       = \"N\";\n    pstprcs_oof        = \"Y\";\n    pstprcs_train      = \"Y\";\n    ML                 = \"Y\";\n    use_orig_allfolds  = \"N\";\n    n_splits           = 5 ;\n    n_repeats          = 5 ;\n    nbrnd_erly_stp     = 50 ;\n    mdlcv_mthd         = 'RSKF';\n    \n    # Ensemble:-    \n    ensemble_req       = \"Y\";\n    enscv_mthd         = \"RSKF\";\n    metric_obj         = 'maximize';\n    ntrials            = 10 if test_req == \"Y\" else 200;\n    \n    # Global variables for plotting:-\n    grid_specs = {'visible': True, 'which': 'both', 'linestyle': '--', \n                           'color': 'lightgrey', 'linewidth': 0.75};\n    title_specs = {'fontsize': 9, 'fontweight': 'bold', 'color': 'tab:blue'};\n\nprint();\nPrintColor(f\"--> Configuration done!\\n\");\ncollect();","metadata":{"execution":{"iopub.status.busy":"2023-09-12T22:43:27.278237Z","iopub.execute_input":"2023-09-12T22:43:27.278864Z","iopub.status.idle":"2023-09-12T22:43:27.421024Z","shell.execute_reply.started":"2023-09-12T22:43:27.278817Z","shell.execute_reply":"2023-09-12T22:43:27.419645Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"%%time \n\n# Defining functions to be used throughout the code for common tasks:-\n\n# Scaler to be used for continuous columns:- \nall_scalers = {'Robust': RobustScaler(), \n               'Z': StandardScaler(), \n               'MinMax': MinMaxScaler()\n              };\nscaler      = all_scalers.get(CFG.scl_method);\n\n# Commonly used CV strategies for later usage:-\nall_cv= {'KF'  : KFold(n_splits= CFG.n_splits, shuffle = True, random_state= CFG.state),\n         'RKF' : RKF(n_splits= CFG.n_splits, n_repeats = CFG.n_repeats, random_state= CFG.state),\n         'RSKF': RSKF(n_splits= CFG.n_splits, n_repeats = CFG.n_repeats, random_state= CFG.state),\n         'SKF' : SKF(n_splits= CFG.n_splits, shuffle = True, random_state= CFG.state)\n        };\n\n# Defining the competition metric:-\ndef ScoreMetric(ytrue, ypred)-> float:\n    \"\"\"\n    This function calculates the metric for the competition. \n    ytrue- ground truth array\n    ypred- predictions\n    returns - metric value (float)\n    \"\"\";\n    return f1_score(ytrue, ypred, average = \"micro\");\n\ndef PostProcessPred(preds, post_process = \"N\"):\n    \"\"\"\n    This is an optional post-processing general function, here is not required\n    \"\"\";\n    return preds;\n\n# Defining the scoring for LightGBM and XGBoost:-\ndef ScoreLGBM(ytrue: np.array, ypred: np.array) -> np.float32:\n    \"Defines the custom metric for light GBM classifier\";\n    return ('MicroF1', f1_score(ytrue, np.argmax(ypred, axis=1), average = \"micro\"), True);\n\ndef ScoreXGB(ypred: np.array, dtrain: DMatrix) -> np.float32:\n    \"This function returns the custom metric according to the XGBoost requirements\";  \n    return (\"MicroF1\", f1_score(dtrain.get_label(), np.argmax(ypred, axis=1), average = \"micro\"));\n\ncollect();\nprint();\n","metadata":{"execution":{"iopub.status.busy":"2023-09-12T22:43:27.424981Z","iopub.execute_input":"2023-09-12T22:43:27.425372Z","iopub.status.idle":"2023-09-12T22:43:27.572112Z","shell.execute_reply.started":"2023-09-12T22:43:27.425337Z","shell.execute_reply":"2023-09-12T22:43:27.570848Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<a id=\"2.2\"></a>\n## <div style= \"font-family: Cambria; font-weight:bold; letter-spacing: 0px; color:#ffffff; font-size:120%; text-align:left;padding:3.0px; background: #0059b3; border-bottom: 8px solid #e6e6e6\" > CONFIGURATION PARAMETERS<br><div> \n\n\n| Parameter         | Description                                             | Possible value choices|\n| ---               | ---                                                     | :-:                   |\n|  version_nb       | Version Number                                          | integer               |\n|  gpu_switch       | GPU switch                                              | ON/OFF                |\n|  state            | Random state for most purposes                          | integer               |\n|  target           | Target column name                                      | yield                 |\n|  episode          | Episode Number                                          | integer               |\n|  path             | Path for input data files                               |                       |\n|  orig_path        | Path for input original data files                      |                       |\n|  dtl_preproc_req  | Proprocessing required                                  | Y/N                   |    \n|  adv_cv_req       | Adversarial CV required                                 | Y/N                   |\n|  ftre_plots_req   | Feature plots required                                  | Y/N                   |\n|  ftre_imp_req     | Feature importance required                             | Y/N                   |\n|  conjoin_orig_data| Conjoin original data                                   | Y/N                   |\n|  sec_ftre_req     | Secondary features required                             | Y/N                   |\n|  scale_req        | Scaling required                                        | Y/N                   |\n|  scl_method       | Scaling method                                          | Z/ Robust/ MinMax     |\n|  enc_method       | Encoding method                                         |-                      |\n|  lesion_OH_req    | Encoding method- lesion columns                         | Y/N                   |\n|  tgt_mapper       | Target mapper                                           | dict                  |\n|  baseline_req     | Baseline model required                                 | Y/N                   |\n|  pstprcs_oof      | Post-process OOF after model training                   | Y/N                   |\n|  pstprcs_train    | Post-process OOF during model training for dev-set      | Y/N                   |\n|  ML               | Machine Learning Models                                 | Y/N                   |\n|  use_orig_allfolds| Use original data across all folds                      | Y/N                   |\n|  n_splits         | Number of CV splits                                     | integer               |\n|  n_repeats        | Number of CV repeats                                    | integer               |\n|  nbrnd_erly_stp   | Number of early stopping rounds                         | integer               |\n|  mdl_cv_mthd      | Model CV method name                                    | RKF/ RSKF/ SKF/ KFold |","metadata":{}},{"cell_type":"markdown","source":"<a id=\"2.3\"></a>\n## <div style= \"font-family: Cambria; font-weight:bold; letter-spacing: 0px; color:#ffffff; font-size:120%; text-align:left;padding:3.0px; background: #0059b3; border-bottom: 8px solid #e6e6e6\" > DATASET AND COMPETITION DETAILS<br><div>\n    \n**Data columns**<br>\nThis is available in my disscussion post as below<br>\nhttps://www.kaggle.com/competitions/playground-series-s3e22/discussion/438603https://www.kaggle.com/competitions/playground-series-s3e22/discussion/438603<br>\n<br>\n**Competition details and notebook objectives**<br>\n1. This is a multi-class classification challenge to predict horse survival using the provided features. **F1-micro** is the metric for the challenge<br>\n2. In this starter notebook, we start the assignment with a detailed EDA, feature plots, interaction effects, adversarial CV analysis and develop starter models to initiate the challenge. We will also incorporate other opinions and approaches as we move along the challenge.<br>","metadata":{}},{"cell_type":"markdown","source":"<a id=\"3\"></a>\n# <div style= \"font-family: Cambria; font-weight:bold; letter-spacing: 0px; color:black; font-size:120%; text-align:left;padding:3.0px; background: #cceeff; border-bottom: 8px solid #004466\" > PREPROCESSING<br><div> ","metadata":{}},{"cell_type":"code","source":"%time \n\nclass Preprocessor():\n    \"\"\"\n    This class aims to do the below-\n    1. Read the datasets\n    2. In this case, process the original data\n    3. Check information and description\n    4. Check unique values and nulls\n    5. Collate starting features \n    6. Conjoin train-original data if requested based on Adversarial CV results\n    \"\"\";\n    \n    def __init__(self):\n        self.train    = pd.read_csv(CFG.path + f\"train.csv\", index_col = 'id');\n        self.test     = pd.read_csv(CFG.path + f\"test.csv\", index_col = 'id');\n        self.target   = CFG.target ;\n        self.original = pd.read_csv(CFG.orig_path);\n        self.conjoin_orig_data = CFG.conjoin_orig_data;\n        self.dtl_preproc_req = CFG.dtl_preproc_req;\n        \n        self.sub_fl   = pd.read_csv(CFG.path + f\"sample_submission.csv\");\n        \n        PrintColor(f\"Data shapes - train-test-original = {self.train.shape} {self.test.shape} {self.original.shape}\");\n        \n        PrintColor(f\"\\nTrain set head\", color = Fore.GREEN);\n        display(self.train.head(5).style.format(precision = 3));\n        PrintColor(f\"\\nTest set head\", color = Fore.GREEN);\n        display(self.test.head(5).style.format(precision = 3));\n        PrintColor(f\"\\nOriginal set head\", color = Fore.GREEN);\n        display(self.original.head(5).style.format(precision = 3));\n                 \n        # Resetting original data index:-\n        self.original.index = range(len(self.original));\n        self.original.index+= max(self.test.index) + 1;\n        self.original.index.name = 'id';\n        \n        #  Changing original data column order to match the competition column structure:-\n        self.original = self.original.reindex(self.train.columns, axis=1);\n  \n    def _AddSourceCol(self):\n        self.train['Source'] = \"Competition\";\n        self.test['Source']  = \"Competition\";\n        self.original['Source'] = 'Original';\n        \n        self.strt_ftre = self.test.columns;\n        return self;\n    \n    def _CollateInfoDesc(self):\n        if self.dtl_preproc_req == \"Y\":\n            PrintColor(f\"\\n{'-'*20} Information and description {'-'*20}\\n\", color = Fore.MAGENTA);\n\n            # Creating dataset information and description:\n            for lbl, df in {'Train': self.train, 'Test': self.test, 'Original': self.original}.items():\n                PrintColor(f\"\\n{lbl} description\\n\");\n                display(df.describe(percentiles= [0.05, 0.25, 0.50, 0.75, 0.9, 0.95, 0.99]).\\\n                        transpose().\\\n                        drop(columns = ['count'], errors = 'ignore').\\\n                        drop([CFG.target], axis=0, errors = 'ignore').\\\n                        style.format(formatter = '{:,.2f}').\\\n                        background_gradient(cmap = 'Blues')\n                       );\n\n                PrintColor(f\"\\n{lbl} information\\n\");\n                display(df.info());\n                collect();\n        return self;\n    \n    def _CollateUnqNull(self):\n        \n        if self.dtl_preproc_req == \"Y\":\n            # Dislaying the unique values across train-test-original:-\n            PrintColor(f\"\\nUnique and null values\\n\");\n            _ = pd.concat([self.train[self.strt_ftre].nunique(), \n                           self.test[self.strt_ftre].nunique(), \n                           self.original[self.strt_ftre].nunique(),\n                           self.train[self.strt_ftre].isna().sum(axis=0),\n                           self.test[self.strt_ftre].isna().sum(axis=0),\n                           self.original[self.strt_ftre].isna().sum(axis=0)\n                          ], \n                          axis=1);\n            _.columns = ['Train_Nunq', 'Test_Nunq', 'Original_Nunq', \n                         'Train_Nulls', 'Test_Nulls', 'Original_Nulls'\n                        ];\n\n            display(_.T.style.background_gradient(cmap = 'Blues', axis=1).\\\n                    format(formatter = '{:,.0f}')\n                   );\n            \n        return self;\n       \n    def DoPreprocessing(self):\n        self._AddSourceCol();\n        self._CollateInfoDesc();\n        self._CollateUnqNull();\n        \n        return self; \n        \n    def ConjoinTrainOrig(self):\n        if self.conjoin_orig_data == \"Y\":\n            PrintColor(f\"Train shape before conjoining with original = {self.train.shape}\");\n            train = pd.concat([self.train, self.original], axis=0, ignore_index = True);\n            PrintColor(f\"Train shape after conjoining with original= {train.shape}\");\n            \n            train = train.drop_duplicates();\n            PrintColor(f\"Train shape after de-duping = {train.shape}\");\n            \n            train.index = range(len(train));\n            train.index.name = 'id';\n        \n        else:\n            PrintColor(f\"We are using the competition training data only\");\n            train = self.train;\n        return train;\n          \ncollect();\nprint();","metadata":{"execution":{"iopub.status.busy":"2023-09-12T22:43:27.573996Z","iopub.execute_input":"2023-09-12T22:43:27.574437Z","iopub.status.idle":"2023-09-12T22:43:27.747333Z","shell.execute_reply.started":"2023-09-12T22:43:27.574395Z","shell.execute_reply":"2023-09-12T22:43:27.746137Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"%%time \n\npp = Preprocessor();\npp.DoPreprocessing();\n\nprint();\ncollect();\n","metadata":{"execution":{"iopub.status.busy":"2023-09-12T22:43:27.748774Z","iopub.execute_input":"2023-09-12T22:43:27.749124Z","iopub.status.idle":"2023-09-12T22:43:28.780828Z","shell.execute_reply.started":"2023-09-12T22:43:27.749093Z","shell.execute_reply":"2023-09-12T22:43:28.779588Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## <div style= \"font-family: Cambria; font-weight:bold; letter-spacing: 0px; color:#ffffff; font-size:120%; text-align:left;padding:3.0px; background: #0059b3; border-bottom: 8px solid #e6e6e6\" > INFERENCES<br> <div>","metadata":{}},{"cell_type":"markdown","source":"<div style= \"font-family: Cambria; letter-spacing: 0px; color:#000000; font-size:110%; text-align:left;padding:3.0px; background: #f2f2f2\" >\n1. We have numerical, categorical and object columns<br>\n2. We may ensue null imputation in this challenge<br>\n3. The dataset is very small risking a shakeup<br>\n</div>","metadata":{}},{"cell_type":"markdown","source":"<a id=\"4\"></a>\n# <div style= \"font-family: Cambria; font-weight:bold; letter-spacing: 0px; color:black; font-size:120%; text-align:left;padding:3.0px; background: #cceeff; border-bottom: 8px solid #004466\" > ADVERSARIAL CV<br><div>","metadata":{}},{"cell_type":"code","source":"%%time\n\n# Performing adversarial CV between the 2 specified datasets:-\ndef Do_AdvCV(df1:pd.DataFrame, df2:pd.DataFrame, source1:str, source2:str):\n    \"This function performs an adversarial CV between the 2 provided datasets if needed by the user\";\n    \n    # Adversarial CV per column:-\n    ftre = pp.test.select_dtypes(include = np.number).\\\n    drop(columns = ['id', \"Source\"], errors = 'ignore').columns;\n    adv_cv = {};\n\n    for col in ftre:\n        shuffle_state = np.random.randint(low = 10, high = 100, size= 1);\n\n        full_df = \\\n        pd.concat([df1[[col]].assign(Source = source1), df2[[col]].assign(Source = source2)], \n                  axis=0, ignore_index = True).\\\n        sample(frac = 1.00, random_state = shuffle_state);\n\n        full_df = full_df.assign(Source_Nb = full_df['Source'].eq(source2).astype(np.int8));\n\n        # Checking for adversarial CV:-\n        model = LGBMClassifier(random_state = CFG.state, max_depth = 6, learning_rate = 0.05);\n        cv    = all_cv['SKF'];\n        score = np.mean(cross_val_score(model, \n                                        full_df[[col]], \n                                        full_df.Source_Nb, \n                                        scoring= 'roc_auc', \n                                        cv     = cv)\n                       );\n        adv_cv.update({col: round(score, 4)});\n        collect();\n    \n    del ftre;\n    collect();\n    \n    fig, ax = plt.subplots(1,1,figsize = (12, 5));\n    pd.Series(adv_cv).plot.bar(color = 'tab:blue', ax = ax);\n    ax.axhline(y = 0.60, color = 'red', linewidth = 2.75);\n    ax.grid(**CFG.grid_specs); \n    plt.yticks(np.arange(0.0, 0.81, 0.05));\n    plt.show();\n    \n# Implementing the adversarial CV:-\nif CFG.adv_cv_req == \"Y\":\n    PrintColor(f\"\\n---------- Adversarial CV - Train vs Original ----------\\n\", \n               color = Fore.MAGENTA);\n    Do_AdvCV(df1 = pp.train, df2 = pp.original, source1 = 'Train', source2 = 'Original');\n    \n    PrintColor(f\"\\n---------- Adversarial CV - Train vs Test ----------\\n\", \n               color = Fore.MAGENTA);\n    Do_AdvCV(df1 = pp.train, df2 = pp.test, source1 = 'Train', source2 = 'Test');\n    \n    PrintColor(f\"\\n---------- Adversarial CV - Original vs Test ----------\\n\", \n               color = Fore.MAGENTA);\n    Do_AdvCV(df1 = pp.original, df2 = pp.test, source1 = 'Original', source2 = 'Test');   \n    \nif CFG.adv_cv_req == \"N\":\n    PrintColor(f\"\\nAdversarial CV is not needed\\n\", color = Fore.RED);\n    \ncollect();\nprint();","metadata":{"execution":{"iopub.status.busy":"2023-09-12T22:43:28.782240Z","iopub.execute_input":"2023-09-12T22:43:28.782635Z","iopub.status.idle":"2023-09-12T22:43:28.930184Z","shell.execute_reply.started":"2023-09-12T22:43:28.782592Z","shell.execute_reply":"2023-09-12T22:43:28.928969Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"%%time \n\nprint();\ntrain, test, strt_ftre = pp.ConjoinTrainOrig(), pp.test.copy(deep = True), deepcopy(pp.strt_ftre);\ncat_cols  = test.select_dtypes(include = 'object').columns[:-1];\ncont_cols = \\\ntest.drop(columns = ['lesion_1', 'lesion_2', 'lesion_3', 'hospital_number'], \n          errors = 'ignore'\n         ).\\\nselect_dtypes(exclude = 'object').columns;\n\nPrintColor(f\"\\nCategory columns\\n\");\ndisplay(cat_cols);\nPrintColor(f\"\\nContinuous columns\\n\");\ndisplay(np.array(cont_cols));\nPrintColor(f\"\\nAll columns\\n\");\ndisplay(strt_ftre);\n\nprint();\ncollect();","metadata":{"execution":{"iopub.status.busy":"2023-09-12T22:43:28.934750Z","iopub.execute_input":"2023-09-12T22:43:28.935078Z","iopub.status.idle":"2023-09-12T22:43:29.104942Z","shell.execute_reply.started":"2023-09-12T22:43:28.935049Z","shell.execute_reply":"2023-09-12T22:43:29.103755Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## <div style= \"font-family: Cambria; font-weight:bold; letter-spacing: 0px; color:#ffffff; font-size:120%; text-align:left;padding:3.0px; background: #0059b3; border-bottom: 8px solid #e6e6e6\" > INFERENCES<br><div>","metadata":{}},{"cell_type":"markdown","source":"<div style= \"font-family: Cambria; letter-spacing: 0px; color:#000000; font-size:110%; text-align:left;padding:3.0px; background: #f2f2f2\" >\n1. Train-test belong to the same distribution, we can perhaps rely on the CV score<br>\n2. We need to further check the train-original distribution further, adversarial validation results indicate that we cannot use the original dataset based on a couple of features<br>\n</div>","metadata":{}},{"cell_type":"markdown","source":"<a id=\"5\"></a>\n# <div style= \"font-family: Cambria; font-weight:bold; letter-spacing: 0px; color:black; font-size:120%; text-align:left;padding:3.0px; background: #cceeff; border-bottom: 8px solid #004466\" > VISUALS AND EDA <br><div> \n ","metadata":{}},{"cell_type":"markdown","source":"<a id=\"5.2\"></a>\n## <div style= \"font-family: Cambria; font-weight:bold; letter-spacing: 0px; color:#ffffff; font-size:120%; text-align:left;padding:3.0px; background: #0059b3; border-bottom: 8px solid #e6e6e6\" > TARGET PLOT<br><div>","metadata":{}},{"cell_type":"code","source":"%%time \n\nif CFG.ftre_plots_req == \"Y\":\n    \n    fig, axes = plt.subplots(1,2, figsize = (12, 5), sharey = True, gridspec_kw = {'wspace': 0.35});\n\n    for i, df in tqdm(enumerate([pp.train, pp.original]), \"Target balance ---> \"):\n        ax= axes[i];\n        a = df[CFG.target].value_counts(normalize = True);\n        _ = ax.pie(x = a , labels = a.index.values, \n                   explode      = [0.0, 0.2, 0.2], \n                   startangle   = 40, \n                   shadow       = True, \n                   colors       = ['#3377ff', '#66ffff','#809fff'], \n                   textprops    = {'fontsize': 7, 'fontweight': 'bold', 'color': 'black'},\n                   pctdistance  = 0.60, \n                   autopct = '%1.1f%%'\n                  );\n        df_name = 'Train' if i == 0 else \"Original\";\n        _ = ax.set_title(f\"\\n{df_name} data\\n\", **CFG.title_specs);\n\n    plt.tight_layout();\n    plt.show();\n        \n        \n    \ncollect();\nprint();","metadata":{"execution":{"iopub.status.busy":"2023-09-12T22:43:29.106681Z","iopub.execute_input":"2023-09-12T22:43:29.107897Z","iopub.status.idle":"2023-09-12T22:43:29.716194Z","shell.execute_reply.started":"2023-09-12T22:43:29.107851Z","shell.execute_reply":"2023-09-12T22:43:29.715075Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"%%time \n\n# Assessing target interactions:-\nif CFG.ftre_plots_req == \"Y\":\n    fig, axes = plt.subplots(1,2, figsize = (12, 4), gridspec_kw = {'wspace': 0.2});\n    \n    for i, (lbl, df) in enumerate({\"Train\": pp.train, \"Original\": pp.original}.items()):\n        ax = axes[i];\n        c = ['#3377ff', '#6699cc'];\n        df.groupby(CFG.target).size().plot.bar(ax = ax, color = c[i]);\n        ax.set_title(f\"Target interaction - {lbl} set\", **CFG.title_specs);\n        ax.set(xlabel = \"\");\n        \n    plt.tight_layout();\n    plt.show()\n        ","metadata":{"execution":{"iopub.status.busy":"2023-09-12T22:43:29.717660Z","iopub.execute_input":"2023-09-12T22:43:29.718323Z","iopub.status.idle":"2023-09-12T22:43:30.275169Z","shell.execute_reply.started":"2023-09-12T22:43:29.718274Z","shell.execute_reply":"2023-09-12T22:43:30.274304Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<a id=\"5.4\"></a>\n## <div style= \"font-family: Cambria; font-weight:bold; letter-spacing: 0px; color:#ffffff; font-size:120%; text-align:left;padding:3.0px; background: #0059b3; border-bottom: 8px solid #e6e6e6\" > CATEGORY COLUMN PLOTS<br><div>","metadata":{}},{"cell_type":"code","source":"%%time\n\nif CFG.ftre_plots_req == \"Y\":\n    fig, axes = plt.subplots(len(cat_cols), 3, figsize = (20, len(cat_cols)* 4.5), \n                             gridspec_kw = {'wspace': 0.25, 'hspace': 0.3});\n\n    for i, col in enumerate(cat_cols):\n        ax = axes[i, 0];\n        a = pp.train[col].value_counts(normalize = True);\n        a.sort_index().plot.barh(ax = ax, color = '#007399');\n        ax.set_title(f\"{col}_Train\", **CFG.title_specs);\n        ax.set_xticks(np.arange(0.0, 0.9, 0.05), \n                      labels = np.round(np.arange(0.0, 0.9, 0.05),2), \n                      rotation = 90\n                     );\n        ax.set(xlabel = '', ylabel = '');\n        del a;\n\n        ax = axes[i, 1];\n        a = pp.test[col].value_counts(normalize = True);\n        a.sort_index().plot.barh(ax = ax, color = '#0088cc');\n        ax.set_title(f\"{col}_Test\", **CFG.title_specs);\n        ax.set_xticks(np.arange(0.0, 0.9, 0.05), \n                      labels = np.round(np.arange(0.0, 0.9, 0.05),2), \n                      rotation = 90\n                     );\n        ax.set(xlabel = '', ylabel = '');\n        del a;\n        \n        ax = axes[i, 2];\n        a = pp.original[col].value_counts(normalize = True);\n        a.sort_index().plot.barh(ax = ax, color = '#0047b3');\n        ax.set_title(f\"{col}_Original\", **CFG.title_specs);\n        ax.set_xticks(np.arange(0.0, 0.9, 0.05), \n                      labels = np.round(np.arange(0.0, 0.9, 0.05),2), \n                      rotation = 90\n                     );\n        ax.set(xlabel = '', ylabel = '');\n        del a;       \n    \n    plt.suptitle(f\"Category column plots\", **CFG.title_specs, y= 0.90);\n    plt.tight_layout();\n    plt.show();\n    \nprint();\ncollect();","metadata":{"execution":{"iopub.status.busy":"2023-09-12T22:43:30.276282Z","iopub.execute_input":"2023-09-12T22:43:30.277130Z","iopub.status.idle":"2023-09-12T22:43:48.131759Z","shell.execute_reply.started":"2023-09-12T22:43:30.277098Z","shell.execute_reply":"2023-09-12T22:43:48.130789Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<a id=\"5.5\"></a>\n## <div style= \"font-family: Cambria; font-weight:bold; letter-spacing: 0px; color:#ffffff; font-size:120%; text-align:left;padding:3.0px; background: #0059b3; border-bottom: 8px solid #e6e6e6\" > CONTINUOUS COLUMN PLOTS<br><div>","metadata":{}},{"cell_type":"code","source":"%%time \n\nif CFG.ftre_plots_req == \"Y\":\n    df = pd.concat([pp.train[cont_cols].assign(Source = 'Train'), \n                    pp.test[cont_cols].assign(Source = 'Test'),\n                    pp.original[cont_cols].assign(Source = \"Original\")\n                   ], \n                   axis=0, ignore_index = True\n                  );\n    \n    fig, axes = plt.subplots(len(cont_cols), 4 ,figsize = (16, len(cont_cols) * 4.2), \n                             gridspec_kw = {'hspace': 0.35, 'wspace': 0.3, 'width_ratios': [0.80, 0.20, 0.20, 0.20]});\n    \n    for i,col in enumerate(cont_cols):\n        ax = axes[i,0];\n        sns.kdeplot(data = df[[col, 'Source']], x = col, hue = 'Source', \n                    palette = ['#0039e6', '#ff5500', '#00b300'], \n                    ax = ax, linewidth = 2.1\n                   );\n        ax.set_title(f\"\\n{col}\", **CFG.title_specs);\n        ax.grid(**CFG.grid_specs);\n        ax.set(xlabel = '', ylabel = '');\n        \n        ax = axes[i,1];\n        sns.boxplot(data = df.loc[df.Source == 'Train', [col]], y = col, width = 0.25,\n                    color = '#33ccff', saturation = 0.90, linewidth = 0.90, \n                    fliersize= 2.25,\n                    ax = ax);\n        ax.set(xlabel = '', ylabel = '');\n        ax.set_title(f\"Train\", **CFG.title_specs);\n        \n        ax = axes[i,2];\n        sns.boxplot(data = df.loc[df.Source == 'Test', [col]], y = col, width = 0.25, fliersize= 2.25,\n                    color = '#80ffff', saturation = 0.6, linewidth = 0.90, \n                    ax = ax); \n        ax.set(xlabel = '', ylabel = '');\n        ax.set_title(f\"Test\", **CFG.title_specs);\n        \n        ax = axes[i,3];\n        sns.boxplot(data = df.loc[df.Source == 'Original', [col]], y = col, width = 0.25, fliersize= 2.25,\n                    color = '#99ddff', saturation = 0.6, linewidth = 0.90, \n                    ax = ax); \n        ax.set(xlabel = '', ylabel = '');\n        ax.set_title(f\"Original\", **CFG.title_specs);\n              \n    plt.suptitle(f\"\\nDistribution analysis- continuous columns\\n\", **CFG.title_specs, \n                 y = 0.905, x = 0.50\n                );\n    plt.tight_layout();\n    plt.show();\n    \nprint();\ncollect();","metadata":{"execution":{"iopub.status.busy":"2023-09-12T22:43:48.133129Z","iopub.execute_input":"2023-09-12T22:43:48.133981Z","iopub.status.idle":"2023-09-12T22:43:55.191128Z","shell.execute_reply.started":"2023-09-12T22:43:48.133949Z","shell.execute_reply":"2023-09-12T22:43:55.189358Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<a id=\"5.7\"></a>\n## <div style= \"font-family: Cambria; font-weight:bold; letter-spacing: 0px; color:#ffffff; font-size:120%; text-align:left;padding:3.0px; background: #0059b3; border-bottom: 8px solid #e6e6e6\" > FEATURE INTERACTION AND UNIVARIATE RELATIONS<br><div>\n    \nWe aim to start off with a simple correlation analysis to determine feature relations","metadata":{}},{"cell_type":"code","source":"%%time \n\ndef MakeCorrPlot(df: pd.DataFrame, data_label:str, figsize = (30, 9)):\n    \"\"\"\n    This function develops the correlation plots for the given dataset\n    \"\"\";\n    \n    fig, axes = plt.subplots(1,2, figsize = figsize, gridspec_kw = {'hspace': 0.2, 'wspace': 0.1},\n                             sharey = True\n                            );\n    \n    for i, method in enumerate(['pearson', 'spearman']):\n        corr_ = df.drop(columns = ['id', 'Source'], errors = 'ignore').corr(method = method);\n        ax = axes[i];\n        sns.heatmap(data = corr_,  \n                    annot= True,\n                    fmt= '.2f', \n                    cmap = 'Blues',\n                    annot_kws= {'fontweight': 'bold','fontsize': 6.75}, \n                    linewidths= 1.5, \n                    linecolor='white', \n                    cbar= False, \n                    mask= np.triu(np.ones_like(corr_)),\n                    ax= ax\n                   );\n        ax.set_title(f\"\\n{method.capitalize()} correlation- {data_label}\\n\", **CFG.title_specs);\n        \n    collect();\n    print();\n\n# Implementing correlation analysis:-\nfor lbl, df in {\"Train\": pp.train[cont_cols], \"Test\": pp.test[cont_cols], \"Original\": pp.original[cont_cols]}.items():\n    MakeCorrPlot(df = df, data_label = lbl, figsize = (16,5));\n\nprint();\ncollect();","metadata":{"execution":{"iopub.status.busy":"2023-09-12T22:43:55.192823Z","iopub.execute_input":"2023-09-12T22:43:55.193237Z","iopub.status.idle":"2023-09-12T22:43:58.458926Z","shell.execute_reply.started":"2023-09-12T22:43:55.193201Z","shell.execute_reply":"2023-09-12T22:43:58.457807Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<a id=\"5.9\"></a>\n## <div style= \"font-family: Cambria; font-weight:bold; letter-spacing: 0px; color:#ffffff; font-size:120%; text-align:left;padding:3.0px; background: #0059b3; border-bottom: 8px solid #e6e6e6\" > SURVIVAL ANALYSIS WITH CATEGORY COLUMNS<br> <div>","metadata":{}},{"cell_type":"code","source":"%%time\n\n# Analyzing survival chances across category columns:-\nfig, axes = plt.subplots(len(cat_cols), 4, gridspec_kw = {'hspace': 0.35, 'wspace': 0.35},\n                         figsize = (20, 4 * len(cat_cols)), \n                         sharex = True\n                        );\nfor lbl, mdl_df in tqdm({'Train': train, \"Original\": pp.original}.items()):\n    for i, col in tqdm(enumerate(cat_cols)):\n        df = pd.crosstab(mdl_df[col], mdl_df[CFG.target]);\n        df['Sum_C'] = np.sum(df, axis=1);\n        df1 = df.apply(lambda x: x/ x['Sum_C'], axis=1);\n        \n        if lbl == \"Train\": j = 0;\n        else: j = 2;\n            \n        ax = axes[i,j];\n        sns.heatmap(df.iloc[:, :-1], cmap = 'winter', fmt= ',.0f', annot = True, \n                    cbar = False, linewidths= 1.5, linecolor='white',\n                    annot_kws= {'fontweight': 'bold','fontsize': 6.75},\n                    ax = ax\n                   );\n        ax.set(xlabel = '', ylabel = '');\n        ax.set_title(f\"{col} {lbl}\", **CFG.title_specs);\n\n        ax = axes[i,j+1];\n        sns.heatmap(df1.iloc[:, :-1], cmap = 'icefire', fmt= ',.2%', annot = True, \n                    cbar = False, linewidths= 1.5, linecolor='white',\n                    annot_kws= {'fontweight': 'bold','fontsize': 6.75},\n                    ax = ax\n                   );\n        ax.set(xlabel = '', ylabel = '');\n        ax.set_title(f\"{col}_pct {lbl}\", **CFG.title_specs);\n\n        del df, df1;\n\nplt.suptitle(f\"Survival analysis with category columns\", **CFG.title_specs, y = 0.90);\nplt.tight_layout();   \nplt.show();\n\nprint();\ncollect();","metadata":{"execution":{"iopub.status.busy":"2023-09-12T22:43:58.460808Z","iopub.execute_input":"2023-09-12T22:43:58.461986Z","iopub.status.idle":"2023-09-12T22:45:49.986326Z","shell.execute_reply.started":"2023-09-12T22:43:58.461943Z","shell.execute_reply":"2023-09-12T22:45:49.984848Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<a id=\"5.10\"></a>\n## <div style= \"font-family: Cambria; font-weight:bold; letter-spacing: 0px; color:#ffffff; font-size:120%; text-align:left;padding:3.0px; background: #0059b3; border-bottom: 8px solid #e6e6e6\" > INFERENCES<br> <div>","metadata":{}},{"cell_type":"markdown","source":"<div style= \"font-family: Cambria; letter-spacing: 0px; color:#000000; font-size:110%; text-align:left;padding:3.0px; background: #f2f2f2\" >\n1. Feature selection is a very important part of the assignment. We have lots of features and feature selection will be a differentiator<br>\n2. Quite a few features have outliers. Outlier handling may be another differentiator in this challenge. Certain categorical features have label outliers that are handled while encoding<br>\n3. Columns are not highly correlated. Dimensionality reduction may help here<br>\n4. We will need to encode lots of object columns with different encoder types<br>\n5. Certain key inferences regarding columns (survival) are as below-<br>\n    - Adults<br>\n    - Non-surgical treatments<br>\n    - Normal values in health risk indicators<br>\n6. Lesion 3 is a quasi-constant feature and is superfluous as it is 0 in the test set<br>\n7. Hospital number may provide insights for feature creation perhaps<br>\n8. Lesions are categorical columns as encoded in the subsequent section<br>\n</div>","metadata":{}},{"cell_type":"markdown","source":"<a id=\"6\"></a>\n# <div style= \"font-family: Cambria; font-weight:bold; letter-spacing: 0px; color:black; font-size:120%; text-align:left;padding:3.0px; background: #cceeff; border-bottom: 8px solid #004466\" > DATA TRANSFORMS <br><div> \n    \nThis section aims at creating secondary features, scaling and if necessary, conjoining the competition training and original data tables<br>\n","metadata":{}},{"cell_type":"code","source":"%%time \n\n# Data transforms:-\nclass Xformer(TransformerMixin, BaseEstimator):\n    \"\"\"\n    This class is used to create secondary features from the existing data\n    \"\"\";\n    \n    def __init__(self): pass\n    \n    def fit(self, X, y= None, **params):\n        self.ip_cols = X.columns;\n        return self;\n    \n    def transform(self, X, y= None, **params):       \n        global strt_ftre;\n        df    = X.copy();      \n      \n        if CFG.sec_ftre_req == \"Y\":\n            df['rectal_temp_risk'] = np.where(df.rectal_temp >= 37.8,1,0).astype(np.int8);\n            df['pulse_risk']       = np.where(df.pulse >= 40,1,0).astype(np.int8);\n            df['cell_vol_risk']    = np.where(df.packed_cell_volume >= 50, 1,0).astype(np.int8);\n            df['protein_risk']     = np.where(df.total_protein >= 7.5, 1,0).astype(np.int8);\n                \n        if CFG.sec_ftre_req != \"Y\": \n            PrintColor(f\"Secondary features are not required\", color = Fore.RED);    \n        \n        self.op_cols = df.columns;  \n        return df;\n    \n    def get_feature_names_in(self, X, y=None, **params): \n        return self.ip_cols;    \n    \n    def get_feature_names_out(self, X, y=None, **params): \n        return self.op_cols;\n    \ncollect();\nprint();","metadata":{"execution":{"iopub.status.busy":"2023-09-12T22:45:49.988180Z","iopub.execute_input":"2023-09-12T22:45:49.988698Z","iopub.status.idle":"2023-09-12T22:45:50.240249Z","shell.execute_reply.started":"2023-09-12T22:45:49.988645Z","shell.execute_reply":"2023-09-12T22:45:50.238383Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"%%time \n    \n# Encoding the categorical columns with domain based encoding:-\nclass Encoder(TransformerMixin, BaseEstimator):\n    \"\"\"\n    This class is used to create encoded features from the existing object data\n    \"\"\"; \n    \n    def __init__(self): \n        self.lesion_OH_req = CFG.lesion_OH_req;\n    \n    def fit(self, X, y= None, **params):\n        self.ip_cols = X.columns;\n        return self;\n    \n    def transform(self, X, y= None, **params):\n        \"\"\"\n        This method performs manual label encoding for the category columns and lesion columns.\n        This is done as per the original data instructions- refer the original metadata page for details\n        \"\"\";\n        \n        df = X.copy();\n        df['surgery'] = df['surgery'].map({'no': 1, 'yes': 0}).astype(np.int8);\n        df['age']     = df['age'].map({'adult': 0, 'young': 1}).astype(np.int8);\n        df['temp_of_extremities'] = \\\n        df['temp_of_extremities'].map({'None': 0, \"normal\":1, \"warm\": 2, \"cool\":3, \"cold\":4}).astype(np.int8);\n        df['peripheral_pulse'] = \\\n        df['peripheral_pulse'].map({'NA': 0, \"None\": 0, \n                                      \"normal\":1, \"increased\": 2, \"reduced\":3, \"absent\":4}\n                                  ).astype(np.int8);\n        df['mucous_membrane'] = \\\n        df['mucous_membrane'].map({'NA': 0, \"None\": 0, \"normal\":1, \"normal_pink\":1, \"pink\": 2, \"bright\" : 3,\n                                     \"bright_pink\":3, \"pale_pink\":4 , \"pale_cyanotic\": 5, \n                                     \"bright_red\":6, \"injected\": 6, \"dark_cyanotic\": 7\n                                    }\n                                 ).astype(np.int8);\n        df['capillary_refill_time'] = \\\n        df['capillary_refill_time'].map({'NA': 0, \"None\": 0, \"less_3_sec\":1, \"3\": 2, \"more_3_sec\": 2}).astype(np.int8); \n        df['pain'] = \\\n        df['pain'].map({\"NA\": 0, \"None\": 0, \"alert\" : 1, \"no_pain\": 2, \"depressed\": 3, \n                        \"mild_pain\": 4, 'slight': 3, \"moderate\": 4, \"severe_pain\": 5, \"extreme_pain\": 6\n                       }\n                      ).astype(np.int8);\n        df['peristalsis'] = \\\n        df['peristalsis'].map({\"NA\": 0, \"None\": 0, \"hypermotile\": 1, 'distend_small':1, \n                               \"normal\": 2,\"hypomotile\": 3, \"absent\": 4}\n                             ).astype(np.int8);\n        df['abdominal_distention'] = \\\n        df['abdominal_distention'].map({\"NA\": 0, \"none\": 1, \"slight\": 2, \"moderate\": 3, \"severe\": 4}).astype(np.int8);\n        df['nasogastric_tube'] = \\\n        df['nasogastric_tube'].map({\"NA\": 0, \"none\": 1, \"slight\": 2, \"significant\": 3}).astype(np.int8);\n        df['nasogastric_reflux'] = \\\n        df['nasogastric_reflux'].map({\"NA\": 0, \"none\": 1, 'slight':2, \"less_1_liter\": 2, \"more_1_liter\": 3}).astype(np.int8);\n        df['rectal_exam_feces'] = \\\n        df['rectal_exam_feces'].map({\"NA\": 0, \"None\": 0, \n                                     \"normal\": 1, \"increased\": 3, \"decreased\": 4, \"absent\": 5, 'serosanguious':6}\n                                   ).astype(np.int8);\n        df['abdomen'] = \\\n        df['abdomen'].map({\"NA\": 0, \"None\":0, \n                           \"normal\": 1, \"other\": 2, \"firm\": 3, \"distend_small\": 4, \"distend_large\": 5}\n                         ).astype(np.int8);\n        df['abdomo_appearance'] = \\\n        df['abdomo_appearance'].map({\"NA\": 0, \"None\":0,\"clear\": 1, \"cloudy\": 2, \"serosanguious\": 3}).astype(np.int8);\n        df['surgical_lesion'] = df['surgical_lesion'].map({\"no\": 1, \"yes\": 0}).astype(np.int8);\n        df['cp_data'] = df['cp_data'].map({\"no\": 1, \"yes\": 0}).astype(np.int8);\n        \n        # Encoding the lesions- lesion3 is 0 in the test set so no need to encode it:-\n        if self.lesion_OH_req == \"Y\":\n            df = \\\n            pd.concat([df.drop(columns = ['lesion_1', 'lesion_2', 'lesion_3'], errors = 'ignore'), \n                       pd.get_dummies(df['lesion_1'].astype(str).apply(lambda x: x[0])).\\\n                       astype(np.int8).iloc[:,1:].add_prefix('lesion1_'),\n                       pd.get_dummies(df['lesion_2'].astype(str).apply(lambda x: x[0])\n                                     ).\\\n                       astype(np.int8).iloc[:,1:].add_prefix('lesion2_')\n                      ], axis=1\n                     );   \n        \n        else:\n            df['lesion_1'] = \\\n            df['lesion_1'].astype(str).apply(lambda x: x[0]).astype(np.int8).clip(0,1).astype(np.int8);\n            df['lesion_2'] = \\\n            df['lesion_2'].astype(str).apply(lambda x: x[0]).astype(np.int8).clip(0,1).astype(np.int8);\n            df.drop('lesion_3', axis=1, errors = 'ignore', inplace = True);\n        \n        self.op_cols = df.columns; \n        return df;\n    \n    def get_feature_names_in(self, X, y=None, **params): \n        return self.ip_cols;    \n    \n    def get_feature_names_out(self, X, y=None, **params): \n        return self.op_cols;       \n    \n\ncollect();\nprint();","metadata":{"execution":{"iopub.status.busy":"2023-09-12T22:45:50.242079Z","iopub.execute_input":"2023-09-12T22:45:50.242615Z","iopub.status.idle":"2023-09-12T22:45:50.511238Z","shell.execute_reply.started":"2023-09-12T22:45:50.242541Z","shell.execute_reply":"2023-09-12T22:45:50.510040Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"%%time \n\n# Scaling:-\nclass Scaler(TransformerMixin, BaseEstimator):\n    \"\"\"\n    This class aims to create scaling for the provided dataset\n    \"\"\";\n    \n    def __init__(self, scl_method: str, scale_req: str, scl_cols):\n        self.scl_method = scl_method;\n        self.scale_req  = scale_req;\n        self.scl_cols   = scl_cols;\n        \n    def fit(self,X, y=None, **params):\n        \"This function calculates the train-set parameters for scaling\";\n        \n        self.params          = X[self.scl_cols].describe(percentiles = [0.25, 0.50, 0.75]).drop(['count'], axis=0).T;\n        self.params['iqr']   = self.params['75%'] - self.params['25%'];\n        self.params['range'] = self.params['max'] - self.params['min'];\n        \n        return self;\n    \n    def transform(self,X, y=None, **params):  \n        \"This function transform the relevant scaling columns\";\n        \n        df = X.copy();\n        if self.scale_req == \"Y\":\n            if CFG.scl_method == \"Z\":\n                df[self.scl_cols] = (df[self.scl_cols].values - self.params['mean'].values) / self.params['std'].values;\n            elif CFG.scl_method == \"Robust\":\n                df[self.scl_cols] = (df[self.scl_cols].values - self.params['50%'].values) / self.params['iqr'].values;\n            elif CFG.scl_method == \"MinMax\":\n                df[self.scl_cols] = (df[self.scl_cols].values - self.params['min'].values) / self.params['range'].values;\n        else:\n            PrintColor(f\"Scaling is not needed\", color = Fore.RED);\n    \n        return df;\n    ","metadata":{"execution":{"iopub.status.busy":"2023-09-12T22:45:50.513011Z","iopub.execute_input":"2023-09-12T22:45:50.513442Z","iopub.status.idle":"2023-09-12T22:45:50.529762Z","shell.execute_reply.started":"2023-09-12T22:45:50.513391Z","shell.execute_reply":"2023-09-12T22:45:50.528399Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"%%time\n\nPrintColor(f\"\\n{'='* 20} Data transformation {'='* 20} \\n\");\n\n# Implementing the pipeline:-\nXtrain, ytrain = \\\ntrain.drop(CFG.target, axis=1, errors = 'ignore'), train[CFG.target].map(CFG.tgt_mapper).astype(np.int8);\n\n# Transforming the data:-\nxform = Pipeline(steps = [(\"Imp\", \n                           ColumnTransformer([(\"CImp\", SI(strategy = \"most_frequent\"), cat_cols.to_list() + ['Source'])],\n                                              remainder = SI(strategy = 'mean'),\n                                              verbose_feature_names_out = False\n                                            )\n                          ),\n                          ('Xform', Xformer()), ('Enc', Encoder())\n                         ], verbose = False\n                );\n\nPrintColor(f\"\\n---> Data pipeline structure\\n\");\ndisplay(xform);\n\nPrintColor(f\"\\n---> Post pipeline datasets\\n\");\nXtrain = xform.fit_transform(Xtrain, ytrain);\nXtest  = xform.transform(test);\n\nPrintColor(f\"\\n---> Train data\\n\");\ndisplay(Xtrain.head(5).style.format(precision = 2));\nPrintColor(f\"\\n---> Test data\\n\");\ndisplay(Xtest.head(5).style.format(precision = 2));\n\nPrintColor(f\"\\n---> Train data columns after data pipeline\\n\");\npprint(Xtrain.columns);\n\nPrintColor(f\"\\n---> Test data columns after data pipeline\\n\");\npprint(Xtest.columns);\n\nprint();\ncollect();\n","metadata":{"execution":{"iopub.status.busy":"2023-09-12T22:45:50.532394Z","iopub.execute_input":"2023-09-12T22:45:50.532802Z","iopub.status.idle":"2023-09-12T22:45:50.929557Z","shell.execute_reply.started":"2023-09-12T22:45:50.532769Z","shell.execute_reply":"2023-09-12T22:45:50.928406Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<a id=\"7\"></a>\n# <div style= \"font-family: Cambria; font-weight:bold; letter-spacing: 0px; color:black; font-size:120%; text-align:left;padding:3.0px; background: #cceeff; border-bottom: 8px solid #004466\" > MODEL TRAINING <br><div> \n   ","metadata":{}},{"cell_type":"code","source":"%%time \n\n# Initializing model I-O:-\n\nMdl_Master = \\\n{'CBC': CatBoostClassifier(**{'task_type'           : \"GPU\" if CFG.gpu_switch == \"ON\" else \"CPU\",\n                              'objective'           : 'MultiClass',\n                              'eval_metric'         : 'TotalF1',\n                              'bagging_temperature' : 0.45,\n                              'colsample_bylevel'   : 0.6,\n                              'iterations'          : 1_000,\n                              'learning_rate'       : 0.056,\n                              'od_wait'             : 14,\n                              'max_depth'           : 6,\n                              'l2_leaf_reg'         : 0.45,\n                              'min_data_in_leaf'    : 5,\n                              'random_strength'     : 0.15, \n                              'max_bin'             : 200,\n                              'verbose'             : 0,\n                           }\n                         ), \n\n  'LGBMC': LGBMClassifier(**{'device'            : \"gpu\" if CFG.gpu_switch == \"ON\" else \"cpu\",\n                             'objective'         : 'multiclass',\n                             'metric'            : 'auc_mu',\n                             'boosting_type'     : 'gbdt',\n                             'random_state'      : CFG.state,\n                             'colsample_bytree'  : 0.50,\n                             'subsample'         : 0.65,\n                             'learning_rate'     : 0.08,\n                             'max_depth'         : 5,\n                             'n_estimators'      : 1000,\n                             'num_leaves'        : 45,                    \n                             'reg_alpha'         : 0.0001,\n                             'reg_lambda'        : 3.5,\n                             'verbose'           : -1,\n                         }\n                      ),\n\n  'XGBC': XGBClassifier(**{'tree_method'        : \"gpu_hist\" if CFG.gpu_switch == \"ON\" else \"hist\",\n                           'objective'          : 'multi:softprob',\n                           'random_state'       : CFG.state,\n                           'colsample_bytree'   : 0.60,\n                           'learning_rate'      : 0.08,\n                           'max_depth'          : 4,\n                           'n_estimators'       : 1000,                         \n                           'reg_alpha'          : 0.01,\n                           'reg_lambda'         : 2.25,\n                           'min_child_weight'   : 10,\n                        }\n                       ),\n};\n\nprint();\ncollect();","metadata":{"execution":{"iopub.status.busy":"2023-09-12T22:45:50.931725Z","iopub.execute_input":"2023-09-12T22:45:50.932054Z","iopub.status.idle":"2023-09-12T22:45:51.182033Z","shell.execute_reply.started":"2023-09-12T22:45:50.932026Z","shell.execute_reply":"2023-09-12T22:45:51.180781Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"%%time\n\n# Selecting relevant columns for the train and test sets:-\nPrintColor(f\"\\n{'='* 20} Model I-O initialization {'='* 20} \\n\");\n\ndrop_cols = ['hospital_number'];\nprint(); \n\ntry: \n    Xtrain, Xtest = Xtrain.drop(drop_cols, axis=1,errors = 'ignore'), Xtest.drop(drop_cols, axis=1, errors = 'ignore');\n    pprint(Xtest.columns, depth = 1, width = 10, indent = 5);\nexcept: \n    PrintColor(f\"\\n---> Check the columns selected\\n---> Selected columns-\", color = Fore.RED);\n    pprint(Xtest.columns, depth = 1, width = 10, indent = 5);\n        \n# Initializing output tables for the models:-\nmethods   = [col for col in Mdl_Master.keys() if col.endswith(\"C\")];\nOOF_Preds = pd.DataFrame(columns = [f\"Class{i}\" for i in range(3)]);\nMdl_Preds = pd.DataFrame(index = pp.sub_fl['id'], columns = [f\"Class{i}\" for i in range(3)],\n                         data = np.zeros((len(Xtest),len(methods)))\n                        );\nFtreImp   = pd.DataFrame(index = Xtrain.drop(columns = ['Source'], errors = 'ignore').columns,\n                         columns = methods,\n                         data = np.zeros((len(Xtrain.drop(columns = ['Source'], errors = 'ignore').columns),\n                                          len(methods)\n                                         )\n                                        )\n                        );\n\nPrintColor(f\"\\n---> Selected model options- \");\npprint(methods, depth = 1, width = 100, indent = 5);\n\nprint();\ncollect();","metadata":{"execution":{"iopub.status.busy":"2023-09-12T22:45:51.183323Z","iopub.execute_input":"2023-09-12T22:45:51.185184Z","iopub.status.idle":"2023-09-12T22:45:51.438348Z","shell.execute_reply.started":"2023-09-12T22:45:51.185146Z","shell.execute_reply":"2023-09-12T22:45:51.436978Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"\n   ","metadata":{}},{"cell_type":"code","source":"%%time \n\nif CFG.ML == \"Y\":\n    PrintColor(f\"\\n{'='* 20} Model Training and CV {'='* 20} \\n\");\n    \n    cols_drop = ['id', 'Source', 'Label'];\n    cv        = all_cv.get(CFG.mdlcv_mthd);\n    Xt        = Xtest.copy(deep = True);\n    X,y       = Xtrain.copy(deep = True), ytrain.copy(deep = True);\n    scores    = [];\n    cat_ftre  = [c for c in Xtest.columns if c not in cont_cols.to_list() + ['Source']];\n                \n    # Initializing CV splitting:-       \n    for fold_nb, (train_idx, dev_idx) in tqdm(enumerate(cv.split(X, y))): \n        Xtr  = X.iloc[train_idx].drop(columns = cols_drop, errors = 'ignore');   \n        Xdev = X.iloc[dev_idx].loc[X.Source == \"Competition\"].drop(columns = cols_drop, errors = 'ignore'); \n        ytr  = y.loc[y.index.isin(Xtr.index)];\n        ydev = y.loc[y.index.isin(Xdev.index)];\n        \n        oof_preds  = np.zeros((len(Xdev), len(methods)));\n        mdl_preds  = np.zeros((len(Xt), len(methods)));\n       \n        # Fitting the models:- \n        for method in methods:\n            model = Mdl_Master[method];\n            if method in ['CBR', 'CBC']:    \n                model.fit(Xtr, ytr, \n                          eval_set = [(Xdev, ydev)], \n                          verbose = 0,\n                          early_stopping_rounds = CFG.nbrnd_erly_stp,\n                          cat_features = cat_ftre,\n                         ); \n\n            elif method in ['LGBMR', 'LGBMC']: \n                model.fit(Xtr, ytr, eval_set = [(Xdev, ydev)],\n                          verbose = 0,\n                          callbacks = [log_evaluation(0), \n                                       early_stopping(CFG.nbrnd_erly_stp, verbose = False)\n                                      ], \n                          categorical_feature = cat_ftre,\n                         );\n\n            elif method in ['XGBR', 'XGBC']:        \n                model.fit(Xtr, ytr, eval_set = [(Xdev, ydev)], \n                          verbose = 0,\n                          early_stopping_rounds = CFG.nbrnd_erly_stp,\n                         );            \n\n            else: \n                model.fit(Xtr, ytr); \n                \n            # Collecting predictions and scores and post-processing OOF based on model method:-  \n            oof_preds = oof_preds + model.predict_proba(Xdev);\n            mdl_preds = mdl_preds + model.predict_proba(Xt.drop(columns = cols_drop, errors = 'ignore'));\n            \n            try: FtreImp[method] = FtreImp[method] + model.feature_importances_;\n            except: pass;\n            \n        OOF_Preds = pd.concat([OOF_Preds, pd.DataFrame(oof_preds, index = Xdev.index, \n                                                       columns = [f\"Class{i}\" for i in range(3)])],\n                              axis = 0,\n                              ignore_index = False\n                             );\n        Mdl_Preds = Mdl_Preds + mdl_preds;      \n        \n        # Calculating the fold-level score metric:-        \n        score = ScoreMetric(ydev, np.argmax(oof_preds, axis=1));\n        scores.append(score);\n        \n        num_space = 3 if fold_nb <= 8 else 2;\n        PrintColor(f\"---> Fold{fold_nb + 1}. {' '* num_space} OOF = {score:.5f}\", \n                   color = Fore.MAGENTA\n                  );\n        collect(); \n    PrintColor(f\"\\n---> Mean Std CV score = {np.mean(scores):.5f} +- {np.std(scores):.5f}\\n\");\n    \n    OOF_Preds = OOF_Preds.groupby(level= 0).mean()/ len(methods);\n    for col in range(3): \n        Mdl_Preds[f\"Class{col}\"] = Mdl_Preds[f\"Class{col}\"]/ (CFG.n_splits * CFG.n_repeats * len(methods));\n    \n    \ncollect();\nprint();\n","metadata":{"execution":{"iopub.status.busy":"2023-09-12T22:45:51.440162Z","iopub.execute_input":"2023-09-12T22:45:51.441001Z","iopub.status.idle":"2023-09-12T22:47:22.209336Z","shell.execute_reply.started":"2023-09-12T22:45:51.440964Z","shell.execute_reply":"2023-09-12T22:47:22.208098Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"%%time \n\nif CFG.ML == \"Y\":\n\n    # Analyzing the Ml model results:-\n    fig, axes = plt.subplots(len(methods), 1, figsize = (25, len(methods)* 5), \n                             sharex = True, gridspec_kw= {'hspace': 0.3}\n                            );\n    for i, method in enumerate(methods):\n        ax = axes[i];\n        FtreImp[method].plot.bar(ax = ax, color = 'tab:blue');\n        ax.set_title(f\"Feature Importance - {method}\", **CFG.title_specs);\n        ax.set(xlabel = '', ylabel = '');\n\n    plt.xticks(rotation = 45);\n    plt.tight_layout();\n    plt.show();\n\n    # Plotting the confusion matrix with the results:-\n    fig, ax = plt.subplots(1,1, figsize = (3,3));\n    sns.heatmap(confusion_matrix(ytrain.iloc[0:pp.train.shape[0]].values, \n                                 OOF_Preds.idxmax(axis=1).apply(lambda x: x[-1]).astype(np.int8).values),\n                cbar = None, annot= True, fmt = '.0f',\n                annot_kws= {'fontweight': 'bold','fontsize': 6.75},\n                cmap = 'Pastel1', linewidths = 2, ax = ax\n               );\n    ax.set_title(f\"\\nConfusion matrix\\n\", **CFG.title_specs);\n    plt.show();\n    \ncollect();\nprint();","metadata":{"execution":{"iopub.status.busy":"2023-09-12T22:48:12.864294Z","iopub.execute_input":"2023-09-12T22:48:12.864745Z","iopub.status.idle":"2023-09-12T22:48:14.868826Z","shell.execute_reply.started":"2023-09-12T22:48:12.864709Z","shell.execute_reply":"2023-09-12T22:48:14.867868Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<a id=\"8\"></a>\n# <div style= \"font-family: Cambria; font-weight:bold; letter-spacing: 0px; color:black; font-size:120%; text-align:left;padding:3.0px; background: #cceeff; border-bottom: 8px solid #004466\" > SUBMISSION<br> <div> ","metadata":{}},{"cell_type":"code","source":"%%time \n\nif CFG.ML == \"Y\":\n    pp.sub_fl[CFG.target] = \\\n    Mdl_Preds.\\\n    idxmax(axis=1).\\\n    apply(lambda x: x[-1]).astype(np.int8).\\\n    map({k: v for k, v in zip(CFG.tgt_mapper.values(), CFG.tgt_mapper.keys())}).values;\n\n    PrintColor(f\"\\nTest set predictions\\n\");\n    display(pp.sub_fl.head(5));\n\n    pp.sub_fl.to_csv(f\"Submission_{CFG.version_nb}.csv\", index = None);\n\n    PrintColor(f\"\\nTest set prediction counts\\n\");\n    pprint(Counter(pp.sub_fl[CFG.target]));\n\nprint();\ncollect();","metadata":{"execution":{"iopub.status.busy":"2023-09-12T22:48:21.484489Z","iopub.execute_input":"2023-09-12T22:48:21.484906Z","iopub.status.idle":"2023-09-12T22:48:21.705018Z","shell.execute_reply.started":"2023-09-12T22:48:21.484874Z","shell.execute_reply":"2023-09-12T22:48:21.703790Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<a id=\"9\"></a>\n# <div style= \"font-family: Cambria; font-weight:bold; letter-spacing: 0px; color:#ffffff; font-size:120%; text-align:left;padding:3.0px; background: #0052cc; border-bottom: 8px solid #cc9966\" > NEXT STEPS<br> <div> ","metadata":{}},{"cell_type":"markdown","source":"<div style= \"font-family: Cambria; letter-spacing: 0px; color:#000000; font-size:110%; text-align:left;padding:3.0px; background: #f2f2f2\" >\n1. Better feature engineering<br>\n2. Incorporating the custom metric in GBM<br>\n3. Try better CV oriented tuning<br>\n4. Try some other methods<br>\n</div>","metadata":{}},{"cell_type":"markdown","source":"# <div style= \"font-family: Cambria; font-weight:bold; letter-spacing: 0px; color:blue; font-size:80%; text-align:left;padding:3.0px; background: #lightgrey\" > If you find my work useful, please upvote and share the notebook.<br> Best regards!!<br> <div>\n  ","metadata":{}}],"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}}